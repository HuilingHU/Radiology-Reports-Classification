{\rtf1\ansi\ansicpg936\cocoartf2759
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue255;\red245\green245\blue245;\red0\green0\blue0;
\red19\green118\blue70;\red131\green0\blue165;\red144\green1\blue18;\red86\green65\blue25;\red0\green0\blue109;
\red31\green99\blue128;\red19\green85\blue52;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c100000;\cssrgb\c96863\c96863\c96863;\cssrgb\c0\c0\c0;
\cssrgb\c3529\c52549\c34510;\cssrgb\c59216\c13725\c70588;\cssrgb\c63922\c8235\c8235;\cssrgb\c41569\c32157\c12941;\cssrgb\c0\c6275\c50196;
\cssrgb\c14510\c46275\c57647;\cssrgb\c6667\c40000\c26667;}
\paperw11900\paperh16840\margl1440\margr1440\vieww16560\viewh10360\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 ##Mistrial finetuning\
\
\pard\pardeftab720\partightenfactor0

\f1\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 !\cf0 \strokec4 pip install transformers==\cf5 \strokec5 4.41.2\cf0 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 !\cf0 \strokec4 pip install peft==\cf5 \strokec5 0.10.0\cf0 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 !\cf0 \strokec4 pip install accelerate==\cf5 \strokec5 0.29.2\cf0 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 !\cf0 \strokec4 pip install trl==\cf5 \strokec5 0.8.1\cf0 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 !\cf0 \strokec4 pip install bitsandbytes\cb1 \
\cf2 \cb3 \strokec2 !\cf0 \strokec4 pip install datasets\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 from\cf0 \cb3 \strokec4  huggingface_hub \cf6 \cb3 \strokec6 import\cf0 \cb3 \strokec4  login\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 login()\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 from\cf0 \cb3 \strokec4  transformers \cf6 \cb3 \strokec6 import\cf0 \cb3 \strokec4  AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\cb1 \
\cf6 \cb3 \strokec6 import\cf0 \cb3 \strokec4  torch\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 model_name = \cf7 \cb3 \strokec7 "mistralai/Mistral-7B-Instruct-v0.2"\cf0 \cb1 \strokec4 \
\cb3 bnb_config = BitsAndBytesConfig(\cb1 \
\cb3     load_in_4bit=\cf2 \strokec2 True\cf0 \strokec4 ,\cb1 \
\cb3     bnb_4bit_compute_dtype=torch.bfloat16,\cb1 \
\cb3     bnb_4bit_quant_type=\cf7 \cb3 \strokec7 "nf4"\cf0 \cb3 \strokec4 ,\cb1 \
\cb3 )\cb1 \
\
\cb3 tokenizer = AutoTokenizer.from_pretrained(\cb1 \
\cb3     model_name,\cb1 \
\cb3     trust_remote_code=\cf2 \strokec2 True\cf0 \cb1 \strokec4 \
\cb3 )\cb1 \
\cb3 tokenizer.pad_token = tokenizer.eos_token\cb1 \
\cb3 tokenizer.padding_side = \cf7 \cb3 \strokec7 "right"\cf0 \cb1 \strokec4 \
\
\cb3 model = AutoModelForCausalLM.from_pretrained(\cb1 \
\cb3     model_name,\cb1 \
\cb3     quantization_config=bnb_config,\cb1 \
\cb3     device_map=\cf7 \cb3 \strokec7 "auto"\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     trust_remote_code=\cf2 \strokec2 True\cf0 \cb1 \strokec4 \
\cb3 )\cb1 \
\cb3 model.config.use_cache = \cf2 \strokec2 False\cf0 \strokec4  \cb1 \
\cb3 model.\cf8 \cb3 \strokec8 eval\cf0 \cb3 \strokec4 ()\
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 from\cf0 \cb3 \strokec4  datasets \cf6 \cb3 \strokec6 import\cf0 \cb3 \strokec4  load_dataset, DatasetDict\cb1 \
\
\cb3 dataset = DatasetDict(\{\cb1 \
\cb3     \cf7 \cb3 \strokec7 "train"\cf0 \cb3 \strokec4 : load_dataset(\cf7 \cb3 \strokec7 "json"\cf0 \cb3 \strokec4 , data_files=\cf7 \cb3 \strokec7 "train1.jsonl"\cf0 \cb3 \strokec4 )[\cf7 \cb3 \strokec7 "train"\cf0 \cb3 \strokec4 ],\cb1 \
\cb3     \cf7 \cb3 \strokec7 "validation"\cf0 \cb3 \strokec4 : load_dataset(\cf7 \cb3 \strokec7 "json"\cf0 \cb3 \strokec4 , data_files=\cf7 \cb3 \strokec7 "val1.jsonl"\cf0 \cb3 \strokec4 )[\cf7 \cb3 \strokec7 "train"\cf0 \cb3 \strokec4 ],\cb1 \
\cb3     \cf7 \cb3 \strokec7 "test"\cf0 \cb3 \strokec4 : load_dataset(\cf7 \cb3 \strokec7 "json"\cf0 \cb3 \strokec4 , data_files=\cf7 \cb3 \strokec7 "test1_infer.jsonl"\cf0 \cb3 \strokec4 )[\cf7 \cb3 \strokec7 "train"\cf0 \cb3 \strokec4 ],\cb1 \
\cb3 \})\cb1 \
\cf2 \cb3 \strokec2 def\cf0 \strokec4  \cf8 \cb3 \strokec8 formatting_prompts_train\cf0 \cb3 \strokec4 (\cf9 \cb3 \strokec9 example\cf0 \cb3 \strokec4 ):\cb1 \
\cb3     messages = example[\cf7 \cb3 \strokec7 "messages"\cf0 \cb3 \strokec4 ]\cb1 \
\cb3     user_message = \cf2 \strokec2 None\cf0 \cb1 \strokec4 \
\cb3     assistant_message = \cf2 \strokec2 None\cf0 \cb1 \strokec4 \
\cb3     \cf6 \cb3 \strokec6 for\cf0 \cb3 \strokec4  message \cf2 \strokec2 in\cf0 \strokec4  messages:\cb1 \
\cb3         \cf6 \cb3 \strokec6 if\cf0 \cb3 \strokec4  message[\cf7 \cb3 \strokec7 "role"\cf0 \cb3 \strokec4 ] == \cf7 \cb3 \strokec7 "user"\cf0 \cb3 \strokec4 :\cb1 \
\cb3             user_message = message[\cf7 \cb3 \strokec7 "content"\cf0 \cb3 \strokec4 ]\cb1 \
\cb3         \cf6 \cb3 \strokec6 elif\cf0 \cb3 \strokec4  message[\cf7 \cb3 \strokec7 "role"\cf0 \cb3 \strokec4 ] == \cf7 \cb3 \strokec7 "assistant"\cf0 \cb3 \strokec4 :\cb1 \
\cb3             assistant_message = message[\cf7 \cb3 \strokec7 "content"\cf0 \cb3 \strokec4 ]\cb1 \
\
\cb3     \cf6 \cb3 \strokec6 if\cf0 \cb3 \strokec4  user_message \cf2 \strokec2 is\cf0 \strokec4  \cf2 \strokec2 None\cf0 \strokec4  \cf2 \strokec2 or\cf0 \strokec4  assistant_message \cf2 \strokec2 is\cf0 \strokec4  \cf2 \strokec2 None\cf0 \strokec4 :\cb1 \
\cb3         \cf6 \cb3 \strokec6 raise\cf0 \cb3 \strokec4  \cf10 \cb3 \strokec10 ValueError\cf0 \cb3 \strokec4 (\cf7 \cb3 \strokec7 "Missing user or assistant message!"\cf0 \cb3 \strokec4 )\cb1 \
\
\cb3     \cf6 \cb3 \strokec6 return\cf0 \cb3 \strokec4  \{\cb1 \
\cb3         \cf7 \cb3 \strokec7 "note_id"\cf0 \cb3 \strokec4 : example[\cf7 \cb3 \strokec7 "note_id"\cf0 \cb3 \strokec4 ],\cb1 \
\cb3         \cf7 \cb3 \strokec7 "prompt"\cf0 \cb3 \strokec4 : user_message,\cb1 \
\cb3         \cf7 \cb3 \strokec7 "response"\cf0 \cb3 \strokec4 : assistant_message\cb1 \
\cb3     \}\cb1 \
\cf2 \cb3 \strokec2 def\cf0 \strokec4  \cf8 \cb3 \strokec8 formatting_prompts_test\cf0 \cb3 \strokec4 (\cf9 \cb3 \strokec9 example\cf0 \cb3 \strokec4 ):\cb1 \
\cb3     messages = example[\cf7 \cb3 \strokec7 "messages"\cf0 \cb3 \strokec4 ]\cb1 \
\cb3     user_message = \cf2 \strokec2 None\cf0 \cb1 \strokec4 \
\cb3     \cf6 \cb3 \strokec6 for\cf0 \cb3 \strokec4  message \cf2 \strokec2 in\cf0 \strokec4  messages:\cb1 \
\cb3         \cf6 \cb3 \strokec6 if\cf0 \cb3 \strokec4  message[\cf7 \cb3 \strokec7 "role"\cf0 \cb3 \strokec4 ] == \cf7 \cb3 \strokec7 "user"\cf0 \cb3 \strokec4 :\cb1 \
\cb3             user_message = message[\cf7 \cb3 \strokec7 "content"\cf0 \cb3 \strokec4 ]\cb1 \
\cb3     \cf6 \cb3 \strokec6 if\cf0 \cb3 \strokec4  user_message \cf2 \strokec2 is\cf0 \strokec4  \cf2 \strokec2 None\cf0 \strokec4 :\cb1 \
\cb3         \cf6 \cb3 \strokec6 raise\cf0 \cb3 \strokec4  \cf10 \cb3 \strokec10 ValueError\cf0 \cb3 \strokec4 (\cf7 \cb3 \strokec7 "Missing user message!"\cf0 \cb3 \strokec4 )\cb1 \
\cb3     \cf6 \cb3 \strokec6 return\cf0 \cb3 \strokec4  \{\cb1 \
\cb3         \cf7 \cb3 \strokec7 "note_id"\cf0 \cb3 \strokec4 : example[\cf7 \cb3 \strokec7 "note_id"\cf0 \cb3 \strokec4 ],\cb1 \
\cb3         \cf7 \cb3 \strokec7 "prompt"\cf0 \cb3 \strokec4 : user_message\cb1 \
\cb3     \}\cb1 \
\cb3 dataset[\cf7 \cb3 \strokec7 "train"\cf0 \cb3 \strokec4 ] = dataset[\cf7 \cb3 \strokec7 "train"\cf0 \cb3 \strokec4 ].\cf8 \cb3 \strokec8 map\cf0 \cb3 \strokec4 (formatting_prompts_train, remove_columns=dataset[\cf7 \cb3 \strokec7 "train"\cf0 \cb3 \strokec4 ].column_names)\cb1 \
\cb3 dataset[\cf7 \cb3 \strokec7 "validation"\cf0 \cb3 \strokec4 ] = dataset[\cf7 \cb3 \strokec7 "validation"\cf0 \cb3 \strokec4 ].\cf8 \cb3 \strokec8 map\cf0 \cb3 \strokec4 (formatting_prompts_train, remove_columns=dataset[\cf7 \cb3 \strokec7 "validation"\cf0 \cb3 \strokec4 ].column_names)\cb1 \
\cb3 dataset[\cf7 \cb3 \strokec7 "test"\cf0 \cb3 \strokec4 ] = dataset[\cf7 \cb3 \strokec7 "test"\cf0 \cb3 \strokec4 ].\cf8 \cb3 \strokec8 map\cf0 \cb3 \strokec4 (formatting_prompts_test, remove_columns=dataset[\cf7 \cb3 \strokec7 "test"\cf0 \cb3 \strokec4 ].column_names)\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 from\cf0 \cb3 \strokec4  peft \cf6 \cb3 \strokec6 import\cf0 \cb3 \strokec4  LoraConfig, get_peft_model, prepare_model_for_kbit_training\cb1 \
\cb3 lora_config = LoraConfig(\cb1 \
\cb3     r=\cf11 \cb3 \strokec11 8\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     lora_alpha=\cf11 \cb3 \strokec11 16\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     target_modules=[\cf7 \cb3 \strokec7 "q_proj"\cf0 \cb3 \strokec4 , \cf7 \cb3 \strokec7 "k_proj"\cf0 \cb3 \strokec4 , \cf7 \cb3 \strokec7 "v_proj"\cf0 \cb3 \strokec4 , \cf7 \cb3 \strokec7 "o_proj"\cf0 \cb3 \strokec4 ],\cb1 \
\cb3     lora_dropout=\cf11 \cb3 \strokec11 0.05\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     bias=\cf7 \cb3 \strokec7 "none"\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     task_type=\cf7 \cb3 \strokec7 "CAUSAL_LM"\cf0 \cb1 \strokec4 \
\cb3 )\cb1 \
\cb3 model = prepare_model_for_kbit_training(model)\cb1 \
\cb3 model = get_peft_model(model, lora_config)\cb1 \
\cb3 model.print_trainable_parameters()\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 from\cf0 \cb3 \strokec4  transformers \cf6 \cb3 \strokec6 import\cf0 \cb3 \strokec4  TrainingArguments\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 training_args = TrainingArguments(\cb1 \
\cb3     output_dir=\cf7 \cb3 \strokec7 "./mistral_lora_finetune"\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     per_device_train_batch_size=\cf11 \cb3 \strokec11 1\cf0 \cb3 \strokec4 , \cb1 \
\cb3     per_device_eval_batch_size=\cf11 \cb3 \strokec11 1\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     gradient_accumulation_steps=\cf11 \cb3 \strokec11 8\cf0 \cb3 \strokec4 , \cb1 \
\cb3     evaluation_strategy=\cf7 \cb3 \strokec7 "steps"\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     eval_steps=\cf11 \cb3 \strokec11 100\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     save_steps=\cf11 \cb3 \strokec11 200\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     save_total_limit=\cf11 \cb3 \strokec11 1\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     num_train_epochs=\cf11 \cb3 \strokec11 3\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     learning_rate=\cf11 \cb3 \strokec11 2e-4\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     warmup_ratio=\cf11 \cb3 \strokec11 0.1\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     logging_steps=\cf11 \cb3 \strokec11 10\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     bf16=\cf2 \strokec2 True\cf0 \strokec4 , \cb1 \
\cb3     fp16=\cf2 \strokec2 False\cf0 \strokec4 , \cb1 \
\cb3     report_to=\cf7 \cb3 \strokec7 "none"\cf0 \cb1 \strokec4 \
\cb3 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 from\cf0 \cb3 \strokec4  trl \cf6 \cb3 \strokec6 import\cf0 \cb3 \strokec4  SFTTrainer\cb1 \
\cf6 \cb3 \strokec6 from\cf0 \cb3 \strokec4  transformers \cf6 \cb3 \strokec6 import\cf0 \cb3 \strokec4  DataCollatorForLanguageModeling\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 trainer = SFTTrainer(\cb1 \
\cb3     model=model,\cb1 \
\cb3     args=training_args,\cb1 \
\cb3     train_dataset=dataset[\cf7 \cb3 \strokec7 "train"\cf0 \cb3 \strokec4 ],\cb1 \
\cb3     eval_dataset=dataset[\cf7 \cb3 \strokec7 "validation"\cf0 \cb3 \strokec4 ],\cb1 \
\cb3     tokenizer=tokenizer,\cb1 \
\cb3     dataset_text_field=\cf7 \cb3 \strokec7 "prompt"\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=\cf2 \strokec2 False\cf0 \strokec4 ),\cb1 \
\cb3 )\cb1 \
\cb3 train_losses = []\cb1 \
\cb3 val_losses = []\cb1 \
\cb3 steps = []\cb1 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 \
from\cf0 \cb3 \strokec4  transformers \cf6 \cb3 \strokec6 import\cf0 \cb3 \strokec4  TrainerCallback\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 class\cf0 \strokec4  \cf10 \cb3 \strokec10 LossRecorderCallback\cf0 \cb3 \strokec4 (\cf10 \cb3 \strokec10 TrainerCallback\cf0 \cb3 \strokec4 ):\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3     \cf2 \strokec2 def\cf0 \strokec4  \cf8 \cb3 \strokec8 on_log\cf0 \cb3 \strokec4 (\cf9 \cb3 \strokec9 self\cf0 \cb3 \strokec4 , \cf9 \cb3 \strokec9 args\cf0 \cb3 \strokec4 , \cf9 \cb3 \strokec9 state\cf0 \cb3 \strokec4 , \cf9 \cb3 \strokec9 control\cf0 \cb3 \strokec4 , \cf9 \cb3 \strokec9 logs\cf0 \cb3 \strokec4 =\cf2 \strokec2 None\cf0 \strokec4 , **\cf9 \cb3 \strokec9 kwargs\cf0 \cb3 \strokec4 ):\cb1 \
\cb3         \cf6 \cb3 \strokec6 if\cf0 \cb3 \strokec4  logs \cf2 \strokec2 is\cf0 \strokec4  \cf2 \strokec2 not\cf0 \strokec4  \cf2 \strokec2 None\cf0 \strokec4 :\cb1 \
\cb3             \cf6 \cb3 \strokec6 if\cf0 \cb3 \strokec4  \cf7 \cb3 \strokec7 "loss"\cf0 \cb3 \strokec4  \cf2 \strokec2 in\cf0 \strokec4  logs:\cb1 \
\cb3                 train_losses.append(logs[\cf7 \cb3 \strokec7 "loss"\cf0 \cb3 \strokec4 ])\cb1 \
\cb3                 steps.append(state.global_step)\cb1 \
\cb3             \cf6 \cb3 \strokec6 if\cf0 \cb3 \strokec4  \cf7 \cb3 \strokec7 "eval_loss"\cf0 \cb3 \strokec4  \cf2 \strokec2 in\cf0 \strokec4  logs:\cb1 \
\cb3                 val_losses.append(logs[\cf7 \cb3 \strokec7 "eval_loss"\cf0 \cb3 \strokec4 ])\cb1 \
\cb3 trainer.add_callback(LossRecorderCallback)\cb1 \
\cb3 trainer.train()\cb1 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 import\cf0 \cb3 \strokec4  matplotlib.pyplot \cf6 \cb3 \strokec6 as\cf0 \cb3 \strokec4  plt\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 plt.figure(figsize=(\cf11 \cb3 \strokec11 10\cf0 \cb3 \strokec4 ,\cf11 \cb3 \strokec11 6\cf0 \cb3 \strokec4 ))\cb1 \
\cb3 plt.plot(steps, train_losses, label=\cf7 \cb3 \strokec7 "Training Loss"\cf0 \cb3 \strokec4 )\cb1 \
\cb3 plt.plot(steps[:\cf8 \cb3 \strokec8 len\cf0 \cb3 \strokec4 (val_losses)], val_losses, label=\cf7 \cb3 \strokec7 "Validation Loss"\cf0 \cb3 \strokec4 )\cb1 \
\cb3 plt.xlabel(\cf7 \cb3 \strokec7 "Step"\cf0 \cb3 \strokec4 )\cb1 \
\cb3 plt.ylabel(\cf7 \cb3 \strokec7 "Loss"\cf0 \cb3 \strokec4 )\cb1 \
\cb3 plt.title(\cf7 \cb3 \strokec7 "Training and Validation Loss during Fine-tuning"\cf0 \cb3 \strokec4 )\cb1 \
\cb3 plt.legend()\cb1 \
\cb3 plt.grid()\cb1 \
\cb3 plt.show()\cb1 \
\
\cb3 output_dir = \cf7 \cb3 \strokec7 "./mistral_lora_finetune_adapter"\cf0 \cb1 \strokec4 \
\cb3 model.save_pretrained(output_dir)\cb1 \
\cb3 tokenizer.save_pretrained(output_dir)\cb1 \
\pard\pardeftab720\partightenfactor0
\cf8 \cb3 \strokec8 print\cf0 \cb3 \strokec4 (\cf2 \strokec2 f\cf7 \cb3 \strokec7 "have saved to the \cf0 \cb3 \strokec4 \{output_dir\} \cf7 \cb3 \strokec7 directory"\cf0 \cb3 \strokec4 )\
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 from\cf0 \cb3 \strokec4  peft \cf6 \cb3 \strokec6 import\cf0 \cb3 \strokec4  PeftModel, PeftConfig\cb1 \
\cf6 \cb3 \strokec6 from\cf0 \cb3 \strokec4  transformers \cf6 \cb3 \strokec6 import\cf0 \cb3 \strokec4  AutoModelForCausalLM, AutoTokenizer\cb1 \
\
\cb3 base_model = AutoModelForCausalLM.from_pretrained(\cb1 \
\cb3     model_name,\cb1 \
\cb3     device_map=\cf7 \cb3 \strokec7 "auto"\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     torch_dtype=torch.bfloat16,\cb1 \
\cb3     trust_remote_code=\cf2 \strokec2 True\cf0 \cb1 \strokec4 \
\cb3 )\cb1 \
\cb3 tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=\cf2 \strokec2 True\cf0 \strokec4 )\cb1 \
\cb3 lora_model = PeftModel.from_pretrained(base_model, \cf7 \cb3 \strokec7 "./mistral_lora_finetune_adapter"\cf0 \cb3 \strokec4 )\cb1 \
\cb3 lora_model.\cf8 \cb3 \strokec8 eval\cf0 \cb3 \strokec4 ()\cb1 \
\cf8 \cb3 \strokec8 print\cf0 \cb3 \strokec4 (\cf7 \cb3 \strokec7 "The fine-tuned LoRA model is loaded\uc0\u65281 "\cf0 \cb3 \strokec4 )\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 import\cf0 \cb3 \strokec4  json\cb1 \
\cf6 \cb3 \strokec6 from\cf0 \cb3 \strokec4  tqdm \cf6 \cb3 \strokec6 import\cf0 \cb3 \strokec4  tqdm\cb1 \
\cb3 output_path = \cf7 \cb3 \strokec7 "mistral_test_outputs.jsonl"\cf0 \cb1 \strokec4 \
\cb3 error_path = \cf7 \cb3 \strokec7 "mistral_test_errors.jsonl"\cf0 \cb1 \strokec4 \
\cf6 \cb3 \strokec6 with\cf0 \cb3 \strokec4  \cf8 \cb3 \strokec8 open\cf0 \cb3 \strokec4 (output_path, \cf7 \cb3 \strokec7 "w"\cf0 \cb3 \strokec4 , encoding=\cf7 \cb3 \strokec7 "utf-8"\cf0 \cb3 \strokec4 ) \cf6 \cb3 \strokec6 as\cf0 \cb3 \strokec4  fout, \cf8 \cb3 \strokec8 open\cf0 \cb3 \strokec4 (error_path, \cf7 \cb3 \strokec7 "w"\cf0 \cb3 \strokec4 , encoding=\cf7 \cb3 \strokec7 "utf-8"\cf0 \cb3 \strokec4 ) \cf6 \cb3 \strokec6 as\cf0 \cb3 \strokec4  ferr:\cb1 \
\cb3     \cf6 \cb3 \strokec6 for\cf0 \cb3 \strokec4  example \cf2 \strokec2 in\cf0 \strokec4  tqdm(dataset[\cf7 \cb3 \strokec7 "test"\cf0 \cb3 \strokec4 ]):\cb1 \
\cb3         \cf6 \cb3 \strokec6 try\cf0 \cb3 \strokec4 :\cb1 \
\cb3             prompt = example[\cf7 \cb3 \strokec7 "prompt"\cf0 \cb3 \strokec4 ]\cb1 \
\cb3             note_id = example[\cf7 \cb3 \strokec7 "note_id"\cf0 \cb3 \strokec4 ]\cb1 \
\
\cb3             input_text = \cf2 \strokec2 f\cf7 \cb3 \strokec7 "<s>[INST] Please read following radiology report and identify the following information. Please output the result in JSON format as follows\uc0\u65306 \'94\cf0 \cb3 \strokec4  \\\cb1 \
\cb3              \cf7 \cb3 \strokec7 \'93\{\\\'94examination type\\\'94: \\"\\", \\\'94examination area\\\'94: [\\"\\"], \\\'94interventional procedure\\\'94: [\\"\\"]\}\uc0\u12290 "\cf0 \cb3 \strokec4  \\\cb1 \
\cb3              \cf2 \strokec2 f\cf7 \cb3 \strokec7 "\\nReports\uc0\u65306 \cf0 \cb3 \strokec4 \{prompt.strip()\}\cf7 \cb3 \strokec7  [/INST]"\cf0 \cb1 \strokec4 \
\
\cb3             inputs = tokenizer(input_text, return_tensors=\cf7 \cb3 \strokec7 "pt"\cf0 \cb3 \strokec4 ).to(lora_model.device)\cb1 \
\
\cb3             outputs = lora_model.generate(\cb1 \
\cb3     **inputs,\cb1 \
\cb3     max_new_tokens=\cf11 \cb3 \strokec11 512\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     do_sample=\cf2 \strokec2 False\cf0 \strokec4 ,\cb1 \
\cb3     temperature=\cf11 \cb3 \strokec11 0.7\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     top_p=\cf11 \cb3 \strokec11 0.9\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     repetition_penalty=\cf11 \cb3 \strokec11 1.1\cf0 \cb3 \strokec4 ,\cb1 \
\cb3     eos_token_id=tokenizer.eos_token_id\cb1 \
\cb3 )\cb1 \
\cb3             reply = tokenizer.decode(outputs[\cf11 \cb3 \strokec11 0\cf0 \cb3 \strokec4 ], skip_special_tokens=\cf2 \strokec2 True\cf0 \strokec4 ).strip()\cb1 \
\
\cb3             fout.write(json.dumps(\{\cb1 \
\cb3                 \cf7 \cb3 \strokec7 "note_id"\cf0 \cb3 \strokec4 : note_id,\cb1 \
\cb3                 \cf7 \cb3 \strokec7 "prompt"\cf0 \cb3 \strokec4 : prompt,\cb1 \
\cb3                 \cf7 \cb3 \strokec7 "reply"\cf0 \cb3 \strokec4 : reply\cb1 \
\cb3             \}, ensure_ascii=\cf2 \strokec2 False\cf0 \strokec4 ) + \cf7 \cb3 \strokec7 "\\n"\cf0 \cb3 \strokec4 )\cb1 \
\cb3         \cf6 \cb3 \strokec6 except\cf0 \cb3 \strokec4  Exception \cf6 \cb3 \strokec6 as\cf0 \cb3 \strokec4  e:\cb1 \
\cb3             ferr.write(json.dumps(\{\cb1 \
\cb3                 \cf7 \cb3 \strokec7 "note_id"\cf0 \cb3 \strokec4 : example.get(\cf7 \cb3 \strokec7 "note_id"\cf0 \cb3 \strokec4 , \cf7 \cb3 \strokec7 "unknown"\cf0 \cb3 \strokec4 ),\cb1 \
\cb3                 \cf7 \cb3 \strokec7 "prompt"\cf0 \cb3 \strokec4 : prompt,\cb1 \
\cb3                 \cf7 \cb3 \strokec7 "error"\cf0 \cb3 \strokec4 : \cf10 \cb3 \strokec10 str\cf0 \cb3 \strokec4 (e)\cb1 \
\cb3             \}, ensure_ascii=\cf2 \strokec2 False\cf0 \strokec4 ) + \cf7 \cb3 \strokec7 "\\n"\cf0 \cb3 \strokec4 )\cb1 \
\cf8 \cb3 \strokec8 print\cf0 \cb3 \strokec4 (\cf7 \cb3 \strokec7 "Test set completed! Output file:"\cf0 \cb3 \strokec4 , output_path)\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \
}