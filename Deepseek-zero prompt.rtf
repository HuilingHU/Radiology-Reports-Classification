{\rtf1\ansi\ansicpg936\cocoartf2759
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue255;\red245\green245\blue245;\red0\green0\blue0;
\red131\green0\blue165;\red144\green1\blue18;\red86\green65\blue25;\red245\green245\blue245;\red19\green85\blue52;
\red31\green99\blue128;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c100000;\cssrgb\c96863\c96863\c96863;\cssrgb\c0\c0\c0;
\cssrgb\c59216\c13725\c70588;\cssrgb\c63922\c8235\c8235;\cssrgb\c41569\c32157\c12941;\cssrgb\c96863\c96863\c96863;\cssrgb\c6667\c40000\c26667;
\cssrgb\c14510\c46275\c57647;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 ## Deepseek zero prompt\
\pard\pardeftab720\partightenfactor0

\f1\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \
!\cf0 \strokec4 pip install -U transformers accelerate peft bitsandbytes --quiet\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 from\cf0 \cb3 \strokec4  transformers \cf5 \cb3 \strokec5 import\cf0 \cb3 \strokec4  AutoTokenizer, AutoModelForCausalLM\cb1 \
\cf5 \cb3 \strokec5 import\cf0 \cb3 \strokec4  torch\cb1 \
\cf5 \cb3 \strokec5 import\cf0 \cb3 \strokec4  os\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 model_name = \cf6 \cb3 \strokec6 "deepseek-ai/deepseek-llm-7b-chat"\cf0 \cb1 \strokec4 \
\cb3 offload_path = \cf6 \cb3 \strokec6 "/content/offload_folder"\cf0 \cb1 \strokec4 \
\cb3 os.makedirs(offload_path, exist_ok=\cf2 \strokec2 True\cf0 \strokec4 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 !\cf0 \strokec4 huggingface-cli login\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 tokenizer = AutoTokenizer.from_pretrained(\cb1 \
\cb3     model_name,\cb1 \
\cb3     trust_remote_code=\cf2 \strokec2 True\cf0 \strokec4 ,\cb1 \
\cb3     use_auth_token=\cf2 \strokec2 True\cf0 \cb1 \strokec4 \
\cb3 )\cb1 \
\cb3 model = AutoModelForCausalLM.from_pretrained(\cb1 \
\cb3     model_name,\cb1 \
\cb3     device_map=\cf6 \cb3 \strokec6 "auto"\cf0 \cb3 \strokec4 , \cb1 \
\cb3     torch_dtype=torch.float16,\cb1 \
\cb3     trust_remote_code=\cf2 \strokec2 True\cf0 \strokec4 ,\cb1 \
\cb3     offload_folder=offload_path,\cb1 \
\cb3     use_auth_token=\cf2 \strokec2 True\cf0 \strokec4 ,\cb1 \
\cb3     local_files_only=\cf2 \strokec2 False\cf0 \strokec4  \cb1 \
\cb3 )\cb1 \
\cb3 model.\cf7 \cb3 \strokec7 eval\cf0 \cb3 \strokec4 ()\cb1 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 print\cf0 \cb3 \strokec4 (\cf6 \cb3 \strokec6 "The model is loaded and the device is mapped as follows\uc0\u65306 "\cf0 \cb3 \strokec4 )\cb1 \
\cf7 \cb3 \strokec7 print\cf0 \cb3 \strokec4 (model.hf_device_map)\
\
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 import\cf0 \cb3 \strokec4  json\cb1 \
\cf5 \cb3 \strokec5 from\cf0 \cb3 \strokec4  tqdm \cf5 \cb3 \strokec5 import\cf0 \cb3 \strokec4  tqdm\cb1 \
\cb3 input_path = \cf6 \cb3 \strokec6 "radiology_prompts.jsonl"\cf0 \cb1 \strokec4 \
\cb3 output_path = \cf6 \cb3 \strokec6 "deepseek_outputs.jsonl"\cf0 \cb1 \strokec4 \
\cb3 error_path = \cf6 \cb3 \strokec6 "deepseek_errors.jsonl"\cf0 \cb1 \strokec4 \
\cf5 \cb3 \strokec5 with\cf0 \cb3 \strokec4  \cf7 \cb3 \strokec7 open\cf0 \cb3 \strokec4 (input_path, \cf6 \cb3 \strokec6 "r"\cf0 \cb3 \strokec4 , encoding=\cf6 \cb3 \strokec6 "utf-8"\cf0 \cb3 \strokec4 ) \cf5 \cb3 \strokec5 as\cf0 \cb3 \strokec4  f:\cb1 \
\cb3     lines = f.readlines()\cb1 \
\cf5 \cb3 \strokec5 with\cf0 \cb3 \strokec4  \cf7 \cb3 \strokec7 open\cf0 \cb3 \strokec4 (output_path, \cf6 \cb3 \strokec6 "w"\cf0 \cb3 \strokec4 , encoding=\cf6 \cb3 \strokec6 "utf-8"\cf0 \cb3 \strokec4 ) \cf5 \cb3 \strokec5 as\cf0 \cb3 \strokec4  fout, \\\cb1 \
\cb3      \cf7 \cb3 \strokec7 open\cf0 \cb3 \strokec4 (error_path, \cf6 \cb3 \strokec6 "w"\cf0 \cb3 \strokec4 , encoding=\cf6 \cb3 \strokec6 "utf-8"\cf0 \cb3 \strokec4 ) \cf5 \cb3 \strokec5 as\cf0 \cb3 \strokec4  ferr:\cb1 \
\cb3     \cf5 \cb3 \strokec5 for\cf0 \cb3 \strokec4  line \cf2 \strokec2 in\cf0 \strokec4  tqdm(lines):\cb1 \
\cb3         obj = json.loads(line)\cb1 \
\cb3         note_id = obj[\cf6 \cb3 \strokec6 "note_id"\cf0 \cb3 \strokec4 ]\cb1 \
\cb3         prompt = obj[\cf6 \cb3 \strokec6 "prompt"\cf0 \cb3 \strokec4 ]\cb1 \
\cb3         input_text = \cf2 \strokec2 f\cf6 \cb3 \strokec6 """You are a medical radiology report analysis expert who is good at reading reports and extracting structured content. Please output the following structure in JSON format\uc0\u65306 \cf0 \cb1 \strokec4 \
\cf6 \cb3 \strokec6 \{\{\cf0 \cb1 \strokec4 \
\cf6 \cb3 \strokec6   \cf0 \cb3 \strokec4 \'93\cf6 \cb3 \strokec6 Examination type\'94: \cf0 \cb3 \strokec4 \'93\'94\cf6 \cb3 \strokec6 ,\cf0 \cb1 \strokec4 \
\cf6 \cb3 \strokec6   \cf0 \cb3 \strokec4 \'93\cf6 \cb3 \strokec6 E\cf0 \cb3 \strokec4 xamination area\cb8 \outl0\strokewidth0 \'94\cf6 \cb3 \outl0\strokewidth0 \strokec6 : [],\cf0 \cb1 \strokec4 \
\cf6 \cb3 \strokec6   \cf0 \cb3 \strokec4 \'93\cf6 \cb3 \strokec6 Interventional procedure\'94: []\cf0 \cb1 \strokec4 \
\cf6 \cb3 \strokec6 \}\}\cf0 \cb1 \strokec4 \
\cf6 \cb3 \strokec6 Radiology Report\uc0\u65306 \cf0 \cb1 \strokec4 \
\cb3 \{prompt\}\cb1 \
\cf6 \cb3 \strokec6 """\cf0 \cb1 \strokec4 \
\cb3         \cf5 \cb3 \strokec5 try\cf0 \cb3 \strokec4 :\cb1 \
\cb3             inputs = tokenizer(input_text, return_tensors=\cf6 \cb3 \strokec6 "pt"\cf0 \cb3 \strokec4 ).to(model.device)\cb1 \
\cb3             outputs = model.generate(**inputs, max_new_tokens=\cf9 \cb3 \strokec9 512\cf0 \cb3 \strokec4 , eos_token_id=tokenizer.eos_token_id)\cb1 \
\cb3             reply = tokenizer.decode(outputs[\cf9 \cb3 \strokec9 0\cf0 \cb3 \strokec4 ], skip_special_tokens=\cf2 \strokec2 True\cf0 \strokec4 ).strip()\cb1 \
\cb3             \cf5 \cb3 \strokec5 if\cf0 \cb3 \strokec4  reply.startswith(\cf6 \cb3 \strokec6 "```json"\cf0 \cb3 \strokec4 ):\cb1 \
\cb3                 reply = reply[\cf7 \cb3 \strokec7 len\cf0 \cb3 \strokec4 (\cf6 \cb3 \strokec6 "```json"\cf0 \cb3 \strokec4 ):].strip()\cb1 \
\cb3             \cf5 \cb3 \strokec5 if\cf0 \cb3 \strokec4  reply.endswith(\cf6 \cb3 \strokec6 "```"\cf0 \cb3 \strokec4 ):\cb1 \
\cb3                 reply = reply[:\cf9 \cb3 \strokec9 -3\cf0 \cb3 \strokec4 ].strip()\cb1 \
\cb3             fout.write(json.dumps(\{\cb1 \
\cb3                 \cf6 \cb3 \strokec6 "note_id"\cf0 \cb3 \strokec4 : note_id,\cb1 \
\cb3                 \cf6 \cb3 \strokec6 "reply"\cf0 \cb3 \strokec4 : reply\cb1 \
\cb3             \}, ensure_ascii=\cf2 \strokec2 False\cf0 \strokec4 ) + \cf6 \cb3 \strokec6 "\\n"\cf0 \cb3 \strokec4 )\cb1 \
\cb3         \cf5 \cb3 \strokec5 except\cf0 \cb3 \strokec4  Exception \cf5 \cb3 \strokec5 as\cf0 \cb3 \strokec4  e:\cb1 \
\cb3             ferr.write(json.dumps(\{\cb1 \
\cb3                 \cf6 \cb3 \strokec6 "note_id"\cf0 \cb3 \strokec4 : note_id,\cb1 \
\cb3                 \cf6 \cb3 \strokec6 "error"\cf0 \cb3 \strokec4 : \cf2 \strokec2 f\cf6 \cb3 \strokec6 "InferenceError: \cf0 \cb3 \strokec4 \{\cf10 \cb3 \strokec10 str\cf0 \cb3 \strokec4 (e)\}\cf6 \cb3 \strokec6 "\cf0 \cb1 \strokec4 \
\cb3             \}, ensure_ascii=\cf2 \strokec2 False\cf0 \strokec4 ) + \cf6 \cb3 \strokec6 "\\n"\cf0 \cb3 \strokec4 )\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \
}